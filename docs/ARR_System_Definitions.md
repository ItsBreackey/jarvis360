# ARR System Definitions & Process Flow

This document describes the terminology, data processing steps, and how the ARR/cohort/NRR features work in this project (jarvis360). Use this as a single source of truth for the dashboard UI tooltips and any future API/analytics changes.

## Key Definitions

- Cohort: a group of customers bucketed by their signup month (first recorded month). In the app, cohorts are generated by `generateCohortTable(records, { dateKey: 'signup_date', valueKey: 'mrr', months: N })`.
- New MRR (monthly): MRR from customers in their first observed month (i.e., signup month). This measures acquisition revenue in that month.
- Expansion MRR (monthly): net positive MRR delta among existing customers compared to previous month (upsells). Computed as sum of positive (thisMonthMRR - prevMonthMRR) per customer.
- Churn MRR (monthly): MRR lost that month from customers who downgrade or cancel. Computed as sum of negative (prevMonthMRR - thisMonthMRR) per customer (or sum of negative deltas expressed as positive lost MRR).
- ARR (Annual Recurring Revenue): usually computed as Total MRR * 12.
- NRR (Net Revenue Retention): (Starting MRR + Expansion - Churn) / Starting MRR for a period (e.g., month-over-month retention). Typically expressed as a percentage.

## Data model and assumptions

- The importer maps CSV columns to fields; the important ones for cohorts and ARR are `signup_date` (or a date column identifying when the customer first appears) and `mrr` (monthly recurring revenue amount). The importer defaults can be adjusted by the user in the Data Dashboard mapping UI.
- Records are stored in-memory in the client. When the backend is available and the user is authenticated, the app may POST uploads to `/api/uploads/` to persist data server-side.
- Missing monthly entries for a customer are treated as zero MRR for cohort aggregation (this is a conservative treatment: absence = no revenue).

## Processing flow (high-level)

1. CSV upload (Data Dashboard)
   - User uploads a CSV and selects column mapping (dateKey and mrrKey at minimum).
   - `parseCSV` normalizes dates and numeric fields and returns an array of records: `{ customer_id, mrr, signup_date, ... }`.

2. In-memory indexing
   - The client stores records in memory. `computeMonthlySeries` and cohort utilities read these records to build time series.

3. Monthly series generation
   - `computeMonthlySeries(records)` aggregates monthly totals and computes deltas per customer month-over-month to derive New/Expansion/Churn series.

4. Cohort table & retention
   - `generateCohortTable` groups customers by cohort (signup month) and creates a 2D table of MRR (or counts) across N months since signup.
   - `generateCohortRetention` computes retention rates per cohort by dividing later-month values by cohort initial-month value.

5. Visualization
   - Overview uses `monthlySeries` to render stacked New/Expansion/Churn and summary cards (Total MRR, NRR estimate, Churned MRR estimate).
   - ARR tab (ArrView) renders cohort table, retention heatmap, charts (area/line) and allows drilldown of customers for a cell.

## UI semantics & tooltips

- The UI shows short definitions in tooltips (accessible `title` and screen-reader text). These are intended to match the precise computations above. If you need richer tooltips (with links to this document), consider wiring a small popover component.

## Edge cases and recommendations

- If your CSV contains transactional data (individual invoices) instead of monthly MRR snapshots, pre-aggregate by customer-month before feeding into the app.
- If you prefer cohort by week/day or by plan type, update `generateCohortTable` call to use a different bucketing function (or add a `cohortKey` param).
- Consider treating missing months as "unknown" instead of zero if your source has sporadic sampling; this requires changes to the cohort aggregation and retention denominator logic.

## Files of interest

- `client/src/utils/cohorts.js` — cohort aggregation, retention, cell drilldown helpers.
- `client/src/utils/csv.js` — parser and CSV helpers.
- `client/src/utils/analytics.js` — monthly series and forecast helpers.
- `client/src/App.jsx` — inlined `ArrView`, Overview, and UI wiring.

## Next improvements (suggested)

- Add a persistent back-end storage option for imported data and for saved dashboards.
- Add explicit UI descriptions (a small help panel) that show exact formulas used for NRR and retention.
- Provide a toggle to treat missing months as `null` (unknown) vs `0` (churn) and recompute cohorts accordingly.

---
## Process workflows (operational runbooks)

Below are step-by-step workflows for the key subsystems. Use these when debugging issues, on-boarding new data sources, or when writing tests / automation.

### Data Intake & Preparation

- Purpose: Accept CSVs from users, map headers to the app's expected fields, normalize dates/numbers, and load into client memory (optionally persist to server when authenticated).
- Inputs: CSV file (user upload), optional persisted header mapping in `localStorage`.
- Outputs: Array of normalized records: `{ customer_id, mrr, signup_date, ... }` and optional server upload to `/api/uploads/`.
- Steps:
   1. User chooses a .csv file in the Data Dashboard UI.
   2. Client reads first N lines to preview headers and populate `previewHeaders`.
   3. Client suggests mappings (date, mrr, id, churn, support, lastActivity) by pattern-matching header names.
   4. User confirms or edits mapping using the HeaderSelector UI.
   5. `parseCSV(csvText, mapping)` is invoked to parse rows, normalize date strings to ISO (YYYY-MM-DD) and numbers to JS Numbers.
   6. App stores parsed records in memory (app state) and emits a `jarvis:data-uploaded` event (UI-only). If authenticated, client attempts `auth.apiFetch('/api/uploads/', { method: 'POST', body: formData })` to persist the file server-side.
   7. UI shows a success toast with the number of rows loaded; server upload warnings are surfaced separately.
- Edge cases / checks:
   - Missing date or mrr columns: show a clear validation error and refuse to load.
   - Percent-style churn values: parse and normalize to 0–1.
   - Transactional vs snapshot data: if transactional, pre-aggregate by customer-month before use.

### Cohort Engine (bucketing and retention)

- Purpose: Build cohort tables and retention matrices from normalized monthly MRR snapshots.
- Inputs: records[] where each record contains at least `{ customer_id, mrr, signup_date }` and optionally per-month rows for customers.
- Outputs: `cohorts` object (`headers`, `rows`), `retention` object (`headers`, `rows`, `retention[]`) and helper lists for drilldown.
- Steps:
   1. Normalize each record's date to the first day of the month for consistent monthly bucketing.
   2. Identify each customer's `signup_month` (first observed month) and build a map: `customerId -> { month -> mrr }`.
   3. For each customer, create a per-cohort row by aligning months relative to the `signup_month` up to `N` months.
   4. `generateCohortTable(records, { dateKey, valueKey, months })` collects totals per cohort-month and returns `headers` (month offsets) and `rows` (cohort label and values[]).
   5. `generateCohortRetention(records, { ... })` computes retention % by dividing each month offset value by the cohort's month-0 value; missing months are treated per project config (default = 0).
   6. The UI heatmap uses `retention.retention` array values 0–100 and colors cells via `colorForPct`.
- Edge cases / checks:
   - New customers with partial months: ensure signup_date normalization avoids off-by-one month errors.
   - Customers with multiple rows in the same month: sum MRR per customer-month before cohort placement.
   - Denominator=0 (empty cohort): avoid divide-by-zero in retention calculations and present N/A or 0% per UX decision.

### Visualization, Drilldown & CSV Export

- Purpose: Render charts (stacked area, bar, line), show cohort heatmap, allow cell drilldown and exporting of CSV snapshots for analysis.
- Inputs: `cohorts`, `retention`, monthly series computed by `computeMonthlySeries`.
- Outputs: On-screen charts and optional downloaded CSV files for cohorts or drilldown rows.
- Steps:
   1. Compose `stackedSeries` with keys for each cohort and values for each month offset.
   2. Render `AreaChart` inside `ResponsiveContainer` for stacked cohort MRR (monthly trend) and small `LineChart` for sparkline.
   3. Render `BarChart` for cohort initial MRR (vertical layout) and generate `tops` list via `topCustomers`.
   4. Render `retention` heatmap table; attach `onClick` handlers to cells to call `listCustomersForCell(records, { cohort, monthIndex })`.
   5. On cell click open a `Modal` showing `drill.rows` (customer_id, mrr, signup_date). Offer an `Export CSV` button that calls `toCSV(rows, headers)` then `downloadCSV(filename, text)`.
   6. Provide small export of full cohort table via `toCSV`/`downloadCSV` (button label: "Export cohorts CSV").
- Edge cases / checks:
   - Very large datasets: avoid building massive DOM tables — recommend server-side pagination or a pre-filter step.
   - CSV encoding: wrap fields with quotes and escape internal quotes. Use `toCSV` helper for consistent behavior.

### Auth flows (register / login / logout / password reset)

- Purpose: Handle cookie-based authentication for server-backed features (server upload, saved dashboards) and support password recovery flows.
- Inputs: user form data (email, password), token-based reset flows from server (email link), local `auth` helper.
- Outputs: authenticated user session (cookie), `auth.me()` responses, and server-side persisted uploads/dashboards.
- Steps:
   1. Register: `auth.register()` calls server endpoint; on success the server sets an authentication cookie. Client calls `auth.me()` to refresh user state and persists minimal profile in memory/localStorage.
   2. Login: `auth.login()` posts credentials; on success server sets cookie; client refreshes user context via `auth.me()` and emits `jarvis:auth-changed`.
   3. Logout: `auth.logout()` revokes cookie server-side and clears client-side state (localStorage tokens are removed); UI updates accordingly.
   4. Forgot/Reset: user requests password reset; server sends an email with a time-limited token link to the reset page. The client submits new password to the reset endpoint; on success user can login normally.
- Edge cases / checks:
   - Ensure server sets SameSite/Lax and Secure cookies appropriately for test and production environments.
   - Test Playwright flows must ensure the backend is running and migrations are applied before running e2e tests (see runbook below).

### Runbook: Stabilizing Playwright e2e tests (quick)

- Purpose: steps to ensure Playwright tests that exercise auth and uploads pass reliably in CI or local dev.
- Steps:
   1. Start Django dev server with migrations applied: `python manage.py migrate && python manage.py runserver 127.0.0.1:8000`.
   2. Ensure `client` dev server or build artifacts are available if e2e loads the client separately. Typically you can run Playwright from `client/` and point tests at the running server.
   3. If tests poll for an API readiness endpoint, increase timeout or add a healthcheck endpoint that returns 200 when migrations & essential services are ready.
   4. Re-run the failing specs with tracing enabled to capture video, HAR and logs for triage.

---
Generated by the UI consolidation task — keep this doc in sync with code changes in `client/src/utils` and `client/src/App.jsx`.
